{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNW2HZVEFhE9oNvyuO3V9G2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Al-Pa-Na/Empathia/blob/main/Empathia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import openai\n",
        "import os\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Setting up OpenAI API key\n",
        "API_KEY = \"Enter you OPENAI API key here\"\n",
        "\n",
        "# Method 1: Set the API key using an environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = API_KEY\n",
        "\n",
        "# Method 2: Set the API key directly\n",
        "openai.api_key = API_KEY"
      ],
      "metadata": {
        "id": "ssMJpdUjE1sM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User memory to store preferences\n",
        "user_memory = {\n",
        "    \"name\": None,  # Stores user's name\n",
        "    \"style\": None,  # Stores user's response style (Buddy, Mom, Mentor)\n",
        "}\n",
        "\n",
        "# Function to get user preferences for personalization\n",
        "def get_user_preferences():\n",
        "    if not user_memory[\"name\"]:\n",
        "        # Ask for user's name if not set\n",
        "        user_memory[\"name\"] = input(\"Hey Buddy! What's your name? \")\n",
        "    if not user_memory[\"style\"]:\n",
        "        # Ask for preferred response style if not set\n",
        "        user_memory[\"style\"] = input(\"Choose your preferred response style - 'Buddy', 'Mom', or 'Mentor': \")\n",
        "    print(f\"Hey {user_memory['name']}! {user_memory['style']} Mode activated.\")"
      ],
      "metadata": {
        "id": "qp09QVXHFHAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate assistant's personality based on user choice\n",
        "def get_personality():\n",
        "    name = user_memory[\"name\"]\n",
        "    style = user_memory[\"style\"]\n",
        "\n",
        "    if style.lower() == 'buddy':\n",
        "        # Friendly and casual assistant\n",
        "        return f'''\n",
        "        You are a friendly, casual assistant. Use a light-hearted tone, often making jokes to keep the mood positive.\n",
        "        Greet users with: \"Hey {name}, what’s up? What’s on your mind today?\"\n",
        "        Cheer up users who feel down with: \"Hey, don’t worry, {name}, things will get better! Wanna talk about it?\"\n",
        "        '''\n",
        "    elif style.lower() == 'mom':\n",
        "        # Caring and comforting assistant\n",
        "        return f'''\n",
        "        You are a caring, comforting assistant. Speak with warmth and empathy, always expressing concern for the user's well-being.\n",
        "        Greet users with: \"Hi {name}, how are you doing today?\"\n",
        "        If the user is feeling down, offer comfort: \"You don’t have to go through this alone, {name}. Let me know if you want to talk.\"\n",
        "        '''\n",
        "    else:\n",
        "        # Wise and supportive mentor assistant\n",
        "        return f'''\n",
        "        You are a wise and supportive mentor. Provide guidance and advice in a calm and professional manner.\n",
        "        Greet users with: \"Hello {name}, how can I help you today?\"\n",
        "        If the user is feeling down, offer constructive support: \"It’s okay, {name}, everyone faces challenges. Let’s see how we can work through it together.\"\n",
        "        '''"
      ],
      "metadata": {
        "id": "9SeaEJIkFNQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to analyze sentiment of the input using TextBlob\n",
        "def analyze_sentiment(user_input):\n",
        "    # Analyze sentiment using TextBlob's polarity score\n",
        "    blob = TextBlob(user_input)\n",
        "    sentiment = blob.sentiment.polarity\n",
        "    if sentiment > 0:\n",
        "        return \"positive\"  # Positive sentiment\n",
        "    elif sentiment < 0:\n",
        "        return \"negative\"  # Negative sentiment\n",
        "    else:\n",
        "        return \"neutral\"  # Neutral sentiment"
      ],
      "metadata": {
        "id": "a27jiREEFPCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initial user preference setup\n",
        "get_user_preferences()\n",
        "\n",
        "# List of messages for context (conversation history)\n",
        "messages = [{\"role\": \"system\", \"content\": get_personality()}]\n",
        "\n",
        "# Start conversation loop\n",
        "while True:\n",
        "    user_input = input(f\"{user_memory['name']}: \")  # Wait for user input\n",
        "    if user_input.lower() == \"end\":\n",
        "        # Exit condition for the loop\n",
        "        print(f\"Goodbye! Take care, {user_memory['name']}!\")\n",
        "        break\n",
        "\n",
        "    # Analyze sentiment of user input\n",
        "    sentiment = analyze_sentiment(user_input)\n",
        "\n",
        "    # Adjust assistant’s response based on sentiment and mode\n",
        "    if sentiment == \"negative\":\n",
        "        if user_memory[\"style\"].lower() == \"buddy\":\n",
        "            messages.append({\"role\": \"assistant\", \"content\": f\"Hey {user_memory['name']}, it’s okay! Things will get better, I promise! Want to chat about it?\"})\n",
        "        elif user_memory[\"style\"].lower() == \"mom\":\n",
        "            messages.append({\"role\": \"assistant\", \"content\": f\"Sweetie, I’m really sorry you're feeling this way. What’s on your mind? I’m here for you.\"})\n",
        "        else:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": f\"{user_memory['name']}, I understand it’s tough. Let’s talk through it and see how we can handle this.\"})\n",
        "    elif sentiment == \"positive\":\n",
        "        if user_memory[\"style\"].lower() == \"buddy\":\n",
        "            messages.append({\"role\": \"assistant\", \"content\": f\"Awesome to hear, {user_memory['name']}! What’s making you feel so good today?\"})\n",
        "        elif user_memory[\"style\"].lower() == \"mom\":\n",
        "            messages.append({\"role\": \"assistant\", \"content\": f\"I’m so happy for you, {user_memory['name']}! What’s been going well?\"})\n",
        "        else:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": f\"Great to hear you’re feeling good, {user_memory['name']}! Keep it up, and let me know if you need any advice.\"})\n",
        "    else:\n",
        "        if user_memory[\"style\"].lower() == \"buddy\":\n",
        "            messages.append({\"role\": \"assistant\", \"content\": f\"Hey {user_memory['name']}, how’s everything going? Anything exciting you want to share?\"})\n",
        "        elif user_memory[\"style\"].lower() == \"mom\":\n",
        "            messages.append({\"role\": \"assistant\", \"content\": f\"Hi {user_memory['name']}, anything on your mind today? I’m here to listen.\"})\n",
        "        else:\n",
        "            messages.append({\"role\": \"assistant\", \"content\": f\"Hello {user_memory['name']}, how can I assist you today?\"})\n",
        "\n",
        "    # Generate response using OpenAI API (GPT-3 or GPT-4)\n",
        "    try:\n",
        "        chat_response = openai.Completion.create(\n",
        "            model=\"gpt-3.5-turbo\",  # Or \"gpt-4\"\n",
        "            messages=messages,  # Conversation history\n",
        "            max_tokens=150,  # Max tokens for the response\n",
        "        )\n",
        "\n",
        "        assistant_reply = chat_response['choices'][0]['text']\n",
        "        print(f\"Assistant: {assistant_reply}\\n\")\n",
        "\n",
        "        # Track token usage for this request\n",
        "        tokens_used = chat_response['usage']['total_tokens']\n",
        "        print(f\"Tokens used in this request: {tokens_used}\")\n",
        "\n",
        "        # Append assistant's reply to the conversation history\n",
        "        messages.append({\"role\": \"assistant\", \"content\": assistant_reply})\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {str(e)}\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "80Sqsi5xFTCl",
        "outputId": "79578ffe-4100-43b8-9350-ed3329a53ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hey Alpana! Mom Mode activated.\n",
            "Alpana: end\n",
            "Goodbye! Take care, Alpana!\n"
          ]
        }
      ]
    }
  ]
}